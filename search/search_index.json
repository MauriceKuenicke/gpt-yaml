{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p> Defining Open AI Prompts using YAML Syntax. </p> <p>Documentation: https://mauricekuenicke.github.io/gpt-yaml/</p> <p>Source Code: https://github.com/MauriceKuenicke/gpt-yaml</p> <p>Use YAML files to store and manage your Open AI prompts.</p>"},{"location":"#important","title":"\u26a0\ufe0f Important","text":"<p>This project is in very early development and currently not safe for use in a production environment. Use at your own risk.</p>"},{"location":"#example","title":"Example","text":"<pre><code># chat_completion.yaml\nmodel: \"gpt-3.5-turbo\"\nsettings:\ntop_p: 1\ntemperature: 1\nchoices: 1\nprompt:\nsystem: You are a helpful assistant.\ncontext:\n- Who won the world series in 2020?\n- The Los Angeles Dodgers won the World Series in 2020.\nmessage: Where was it played?\n</code></pre> <pre><code>from gptyaml.prompts import ChatCompletionPrompt\nimport openai\nprompt = ChatCompletionPrompt.from_file(\"chat_completion.yaml\")\n# Use the configuration directly from the prompt instance\nopenai.ChatCompletion.create(**prompt.cfg)\n# or extract single values\nmodel = prompt.model\nmessages = prompt.messages\nopenai.ChatCompletion.create(model=model, messages=messages)\n</code></pre>"}]}